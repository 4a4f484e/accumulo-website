<p>Before running any of the examples, the following steps must be performed.</p>

<ol>
  <li>
    <p>Install and run Accumulo via the instructions found in $ACCUMULO_HOME/README.
Remember the instance name. It will be referred to as “instance” throughout
the examples. A comma-separated list of zookeeper servers will be referred
to as “zookeepers”.</p>
  </li>
  <li>
    <p>Create an Accumulo user (see the <a href="/1.8/user_manual/Accumulo_Shell.html#User_Administration">user manual</a>), or use the root user.
The “username” Accumulo user name with password “password” is used
throughout the examples. This user needs the ability to create tables.</p>
  </li>
</ol>

<p>In all commands, you will need to replace “instance”, “zookeepers”,
“username”, and “password” with the values you set for your Accumulo instance.</p>

<p>Commands intended to be run in bash are prefixed by ‘$’. These are always
assumed to be run from the $ACCUMULO_HOME directory.</p>

<p>Commands intended to be run in the Accumulo shell are prefixed by ‘&gt;’.</p>

<p>Each README in the examples directory highlights the use of particular
features of Apache Accumulo.</p>

<p>README.batch:       Using the batch writer and batch scanner.</p>

<p>README.bloom:       Creating a bloom filter enabled table to increase query
                       performance.</p>

<p>README.bulkIngest:  Ingesting bulk data using map/reduce jobs on Hadoop.</p>

<p>README.classpath:   Using per-table classpaths.</p>

<p>README.client:      Using table operations, reading and writing data in Java.</p>

<p>README.combiner:    Using example StatsCombiner to find min, max, sum, and
                       count.</p>

<p>README.constraints: Using constraints with tables.</p>

<p>README.dirlist:     Storing filesystem information.</p>

<p>README.export:      Exporting and importing tables.</p>

<p>README.filedata:    Storing file data.</p>

<p>README.filter:      Using the AgeOffFilter to remove records more than 30
                       seconds old.</p>

<p>README.helloworld:  Inserting records both inside map/reduce jobs and
                       outside. And reading records between two rows.</p>

<p>README.isolation:   Using the isolated scanner to ensure partial changes
                       are not seen.</p>

<p>README.mapred:      Using MapReduce to read from and write to Accumulo
                       tables.</p>

<p>README.maxmutation: Limiting mutation size to avoid running out of memory.</p>

<p>README.regex:       Using MapReduce and Accumulo to find data using regular
                       expressions.</p>

<p>README.rowhash:     Using MapReduce to read a table and write to a new
                       column in the same table.</p>

<p>README.sample:      Building and using sample data in Accumulo.</p>

<p>README.shard:       Using the intersecting iterator with a term index
                       partitioned by document.</p>

<p>README.tabletofile: Using MapReduce to read a table and write one of its
                       columns to a file in HDFS.</p>

<p>README.terasort:    Generating random data and sorting it using Accumulo.</p>

<p>README.visibility:  Using visibilities (or combinations of authorizations).
                       Also shows user permissions.</p>

