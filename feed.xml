<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Accumulo™</title>
    <description>The Apache Accumulo™ sorted, distributed key/value store is a robust, scalable, high performance data storage and retrieval system.
</description>
    <link>https://accumulo.apache.org/</link>
    <atom:link href="https://accumulo.apache.org/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 31 May 2017 14:32:53 -0400</pubDate>
    <lastBuildDate>Wed, 31 May 2017 14:32:53 -0400</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>Introducing Uno and Muchos</title>
        <description>&lt;p&gt;While &lt;a href=&quot;https://github.com/apache/accumulo/blob/master/INSTALL.md&quot;&gt;Accumulo’s installation instructions&lt;/a&gt; are simple, it can be time consuming to install Accumulo
given its requirement on &lt;a href=&quot;https://hadoop.apache.org/&quot;&gt;Hadoop&lt;/a&gt; and &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Zookeeper&lt;/a&gt; being installed and running. For a one-time production
installation, this set up time (which can take up to an hour) is not much of an inconvenience. However, it can become a burden
for developers who need to frequently set up Accumulo to test code changes, switch between different
versions, or start a fresh instance on a laptop.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/astralway/uno&quot;&gt;Uno&lt;/a&gt; and &lt;a href=&quot;https://github.com/astralway/muchos&quot;&gt;Muchos&lt;/a&gt; are tools that ease the burden on developers of installing Accumulo and its dependencies.
The names of Uno and Muchos indicate their use case. Uno is designed for running Accumulo on a single node
while Muchos is designed for running Accumulo on a cluster. While Uno and Muchos will install by default the most
recent stable release of Accumulo, Hadoop, and Zookeeper, it is easy to configure different versions to
match a production cluster.&lt;/p&gt;

&lt;p&gt;The sections below show how to use these tools. For more complete documentation, view their respective GitHub
pages.&lt;/p&gt;

&lt;h2 id=&quot;uno&quot;&gt;Uno&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/astralway/uno&quot;&gt;Uno&lt;/a&gt; is a command line tool that sets up Accumulo on a single machine. It can be installed by cloning the
Uno git repo.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/astralway/uno.git
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;uno
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Uno works out of the box but it can be customized by modifying &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/uno.conf&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;First, download the Accumulo, Hadoop, and Zookeeper tarballs from Apache by using the command below:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./bin/uno fetch accumulo
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The fetch command places all tarballs in the &lt;code class=&quot;highlighter-rouge&quot;&gt;downloads/&lt;/code&gt; directory. Uno can be configured (in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/uno.conf&lt;/code&gt;)
to build an Accumulo tarball from a local git repo when &lt;code class=&quot;highlighter-rouge&quot;&gt;fetch&lt;/code&gt; is called.&lt;/p&gt;

&lt;p&gt;After downloading tarballs, the command below sets up Accumulo, Hadoop &amp;amp; Zookeeper in the &lt;code class=&quot;highlighter-rouge&quot;&gt;install/&lt;/code&gt; directory.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./bin/uno setup accumulo
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Accumulo, Hadoop, &amp;amp; Zookeeper are now ready to use. You can view the Accumulo monitor at
&lt;a href=&quot;http://localhost:9995&quot;&gt;http://localhost:9995&lt;/a&gt;. You can configure your shell using the command below:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;./bin/uno env&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Run &lt;code class=&quot;highlighter-rouge&quot;&gt;uno stop accumulo&lt;/code&gt; to cleanly stop your cluster and &lt;code class=&quot;highlighter-rouge&quot;&gt;uno start accumulo&lt;/code&gt; to start it again.&lt;/p&gt;

&lt;p&gt;If you need a fresh cluster, you can run &lt;code class=&quot;highlighter-rouge&quot;&gt;uno setup accumulo&lt;/code&gt; again. To kill your cluster, run &lt;code class=&quot;highlighter-rouge&quot;&gt;uno kill&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;muchos&quot;&gt;Muchos&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/astralway/muchos&quot;&gt;Muchos&lt;/a&gt; is a command line tool that launches an AWS EC2 cluster with Accumulo set up on it. It is installed by
cloning its git repo.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/astralway/muchos.git
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;muchos
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Before using Muchos, create &lt;code class=&quot;highlighter-rouge&quot;&gt;muchos.props&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/&lt;/code&gt; and edit it for your AWS environment.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp conf/muchos.props.example conf/muchos.props
vim conf/muchos.props
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Next, run the command below to launch a cluster in AWS.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;muchos launch -c mycluster
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After launching the cluster, set up Accumulo on it using the following command.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;muchos setup
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;muchos ssh&lt;/code&gt; to ssh to the cluster and &lt;code class=&quot;highlighter-rouge&quot;&gt;muchos terminate&lt;/code&gt; to terminate all EC2 nodes when you are finished.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Uno and Muchos automate installing Accumulo for developmment and testing. While not recommended for production
use at this time, Muchos is a great reference for running Accumulo in production. System admistrators can
reference the &lt;a href=&quot;https://www.ansible.com/&quot;&gt;Ansible&lt;/a&gt; code in Muchos to automate management of their own clusters.&lt;/p&gt;

</description>
        <pubDate>Fri, 21 Apr 2017 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/blog/2017/04/21/introducing-uno-and-muchos.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2017/04/21/introducing-uno-and-muchos.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 1.7.3</title>
        <description>&lt;p&gt;Apache Accumulo 1.7.3 is a maintenance release on the 1.7 version branch. This release contains changes from 79 issues, comprised of bug-fixes, 
performance improvements, build quality improvements, and more. See&lt;br /&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12312121&amp;amp;version=12335841&quot;&gt;JIRA&lt;/a&gt; for a complete list.&lt;/p&gt;

&lt;p&gt;Below are resources for this release:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://accumulo.apache.org/1.7/accumulo_user_manual.html&quot;&gt;User Manual&lt;/a&gt; : In-depth developer and administrator documentation.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://accumulo.apache.org/1.7/apidocs/&quot;&gt;Javadocs&lt;/a&gt;  : Accumulo 1.7.3 API&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://accumulo.apache.org/1.7/examples/&quot;&gt;Examples&lt;/a&gt; : Code with corresponding readme files that give step by step instructions for running example code.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Accumulo follows &lt;a href=&quot;http://semver.org/&quot;&gt;Semantic Versioning&lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/blob/rel/1.7.3/README.md#api&quot;&gt;guidelines&lt;/a&gt;.  This release is a 
“&lt;a href=&quot;http://semver.org/#spec-item-6&quot;&gt;patch version&lt;/a&gt;”, which  means that only backwards compatible bug fixes are introduced in this version. A bug fix is defined as 
an internal change that fixes incorrect behavior. Users of any previous 1.7.x release are strongly encouraged to update as soon as possible to benefit from the 
bug fixes with very little concern in change of underlying functionality.  As always, the Accumulo developers take API compatibility very seriously 
and have invested much time to ensure that we meet the promises set forth to our users. Users of 1.6 or earlier that are seeking to upgrade to 1.7 should 
consider 1.7.3 as a starting point.&lt;/p&gt;

&lt;h2 id=&quot;major-changes&quot;&gt;Major Changes&lt;/h2&gt;

&lt;h3 id=&quot;tablet-server-performance-improvement&quot;&gt;Tablet Server Performance Improvement&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4458&quot;&gt;ACCUMULO-4458&lt;/a&gt; mitigated some contention on the Hadoop configuration instance backing the XML configs 
read for SiteConfiguration. This should improve overall Tablet Server performance.&lt;/p&gt;

&lt;h3 id=&quot;synchronization-issue-with-deep-copies-of-sources&quot;&gt;Synchronization issue with deep copies of sources&lt;/h3&gt;

&lt;p&gt;Deep copies of iterator sources were not thread safe and threw exceptions, mostly down in the ZlibDecompressor library. The real bug was in the 
BoundedRangeFileInputStream. The read() method synchronizes on the underlying FSDataInputStream, however the available() method did not. 
See &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4391&quot;&gt;ACCUMULO-4391&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;system-permission-bug-in-thrift-proxy&quot;&gt;System permission bug in Thrift Proxy&lt;/h3&gt;

&lt;p&gt;The Accumulo Proxy lacked support for the following system permissions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;System.CREATE_NAMESPACE&lt;/li&gt;
  &lt;li&gt;System.DROP_NAMESPACE&lt;/li&gt;
  &lt;li&gt;System.ALTER_NAMESPACE&lt;/li&gt;
  &lt;li&gt;System.OBTAIN_DELEGATION_TOKEN&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Without these permissions, proxy users would get an AccumuloException if attempting
any of those operations.  Fixed in ticket &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4519&quot;&gt;ACCUMULO-4519&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;hostregextableloadbalancer-used-stale-information&quot;&gt;HostRegexTableLoadBalancer used stale information&lt;/h3&gt;

&lt;p&gt;The HostRegexTableLoadBalancer maintains an internal mapping of tablet server pools and tablet server status. It was updated at a configurable interval 
initially as an optimization. Unfortunately it had the negative side effect of providing the assignment and balance operations with stale information. 
This lead to a constant shuffling of tablets. The configuration property was removed so that assign/balance methods get updated information every time. 
See &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4576&quot;&gt;ACCUMULO-4576&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;modify-tableoperations-online-to-check-for-table-state&quot;&gt;Modify TableOperations online to check for table state&lt;/h3&gt;

&lt;p&gt;The table operations online operation executes as a fate operation. If a transaction lock for the table is currently held, this operation will block even 
if no action is needed. &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4574&quot;&gt;ACCUMULO-4574&lt;/a&gt; changes the behavior of the online operation to a NOOP if the 
table is already in the requested state. This returns immediately without queuing a fate operation.&lt;/p&gt;

&lt;h2 id=&quot;other-notable-changes&quot;&gt;Other Notable Changes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4600&quot;&gt;ACCUMULO-4600&lt;/a&gt; Shell does not fall back to accumulo-site.xml when on classpath&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4597&quot;&gt;ACCUMULO-4597&lt;/a&gt; NPE from RFile PrintInfo when RF has more than 1,000 column families.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4488&quot;&gt;ACCUMULO-4488&lt;/a&gt; Fix gap in user manual on Kerberos for clients&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-2724&quot;&gt;ACCUMULO-2724&lt;/a&gt; CollectTabletStats had multiple -t parameter&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4431&quot;&gt;ACCUMULO-4431&lt;/a&gt; Log what random is chosen for a tserver.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4549&quot;&gt;ACCUMULO-4549&lt;/a&gt; Remove duplicate init functions in TabletBalancer&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4467&quot;&gt;ACCUMULO-4467&lt;/a&gt; Random Walk broken because of unmet dependency on commons-math&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4578&quot;&gt;ACCUMULO-4578&lt;/a&gt; Cancel compaction FATE operation does not release namespace lock&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4505&quot;&gt;ACCUMULO-4505&lt;/a&gt; Shell still reads accumulo-site.xml when using Zookeeper CLI options&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4535&quot;&gt;ACCUMULO-4535&lt;/a&gt; HostRegexTableLoadBalancer fails with NullPointerException&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4575&quot;&gt;ACCUMULO-4575&lt;/a&gt; Concurrent table delete operations leave orphan fate transaction locks&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;upgrading&quot;&gt;Upgrading&lt;/h2&gt;

&lt;p&gt;The recommended way to upgrade from a prior 1.7.x release is to stop Accumulo, upgrade to 1.7.3 and then start 1.7.3.&lt;/p&gt;

&lt;p&gt;When upgrading, there is a known issue if the upgrade fails due to outstanding &lt;a href=&quot;https://accumulo.apache.org/1.7/accumulo_user_manual.html#_fault_tolerant_executor_fate&quot;&gt;FATE&lt;/a&gt;
operations, see &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4496&quot;&gt;ACCUMULO-4496&lt;/a&gt; The work around if this situation is encountered:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Start tservers&lt;/li&gt;
  &lt;li&gt;Start shell&lt;/li&gt;
  &lt;li&gt;Run &lt;code class=&quot;highlighter-rouge&quot;&gt;fate print&lt;/code&gt; to list all&lt;/li&gt;
  &lt;li&gt;If completed, just delete with &lt;code class=&quot;highlighter-rouge&quot;&gt;fate delete&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Start masters once there are no more fate operations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If any of the FATE operations are not complete, you should rollback the upgrade and troubleshoot completing them with your prior version. 
When performing an upgrade between major versions, the upgrade is one-way, therefore it is important that you do not have any outstanding 
FATE operations before starting the upgrade.&lt;/p&gt;

&lt;h3 id=&quot;from-16-to-17&quot;&gt;From 1.6 to 1.7&lt;/h3&gt;

&lt;p&gt;Upgrades from 1.6 to 1.7 are be possible with little effort as no changes were made at the data layer and RPC changes
were made in a backwards-compatible way. The recommended way is to stop Accumulo 1.6, perform the Accumulo upgrade to
1.7, and then start 1.7. Like previous versions, after 1.7.0 is started on a 1.6 instance, a one-time upgrade will
happen by the Master which will prevent a downgrade back to 1.6. Upgrades are still one way. Upgrades from versions
prior to 1.6 to 1.7 should follow the below path to 1.6 and then perform the upgrade to 1.7 – direct upgrades to 1.7
for versions other than 1.6 are untested.&lt;/p&gt;

&lt;p&gt;After upgrading to 1.7.0, users will notice the addition of a &lt;code class=&quot;highlighter-rouge&quot;&gt;replication&lt;/code&gt; table in the &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo&lt;/code&gt; namespace. This
table is created and put offline to avoid any additional maintenance if the data-center replication feature is not
in use.&lt;/p&gt;

&lt;p&gt;Existing configuration files from 1.6 should be compared against the examples provided in 1.7. The 1.6 configuration
files should all function with 1.7 code, but you will likely want to include a new file (hadoop-metrics2-accumulo.properties)
to enable the new metrics subsystem. Read the section on Hadoop Metrics2 in the Administration chapter of the Accumulo User Manual.&lt;/p&gt;

&lt;p&gt;For each of the other new features, new configuration properties exist to support the feature. Refer to the added
sections in the User Manual for the feature for information on how to properly configure and use the new functionality.&lt;/p&gt;

&lt;h2 id=&quot;testing&quot;&gt;Testing&lt;/h2&gt;

&lt;p&gt;Each unit and functional test only runs on a single node, while the RandomWalk and Continuous Ingest tests run on any number of nodes. Agitation refers to randomly restarting Accumulo processes and Hadoop Datanode processes, and, in HDFS High-Availability instances, forcing NameNode failover.&lt;/p&gt;

&lt;table id=&quot;release_notes_testing&quot; class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;OS/Environment&lt;/th&gt;
      &lt;th&gt;Hadoop&lt;/th&gt;
      &lt;th&gt;Nodes&lt;/th&gt;
      &lt;th&gt;ZooKeeper&lt;/th&gt;
      &lt;th&gt;HDFS HA&lt;/th&gt;
      &lt;th&gt;Tests&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS 7, openJDK 1.8 from CentOS yum repo, EC2; 1 leader m3.xlarge, 8 workers d2.xlarge&lt;/td&gt;
      &lt;td&gt;2.7.3&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;3.4.9&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;24 HR Continuous Ingest without Agitation&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS 7, openJDK 1.8 from CentOS yum repo, EC2; 1 leader m3.xlarge, 8 workers d2.xlarge&lt;/td&gt;
      &lt;td&gt;2.7.3&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;3.4.9&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;24 HR Continuous Ingest Agitation&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</description>
        <pubDate>Thu, 06 Apr 2017 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-1.7.3/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-1.7.3/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>Happy Anniversary Accumulo</title>
        <description>&lt;p&gt;This month, Apache Accumulo is celebrating five years as a top-level project
at the Apache Software Foundation.&lt;/p&gt;

&lt;p&gt;To celebrate, we got a cake!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/cake.jpg&quot; alt=&quot;&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The community would like to thank everyone that has been a part of Accumulo
over the past years and to those involved before that during its time in the ASF Incubator.&lt;/p&gt;

&lt;p&gt;As always, we look forward to continued activity from everyone. Happy Accumul-ating!&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Mar 2017 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/blog/2017/03/21/happy-anniversary-accumulo.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2017/03/21/happy-anniversary-accumulo.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Security Performance Implications</title>
        <description>
&lt;p&gt;The purpose of this two part series was to measure the performance impact of
various security configurations on a cluster running Apache Accumulo’s
continuous ingest suite. The tests were performed using Amazon Web
Services (AWS), Hortonworks Data Platform 2.4 and Accumulo 1.7. Each of
the five different security settings in Accumulo 1.7 was tested including 
no security, SSL, and SASL with Kerberos authentication for the three quality 
of protection levels (auth, auth-int, auth-conf).  KDC was MIT.  HDFS was 
configured to use Kerberos for authentication and had service level 
authorization on. Other than that, no other security settings (HTTPS, RPC 
protection, data transfer encryption, etc) were enabled.  Timely was a 
separate, single node HDFS/Zookeeper/Accumulo instance.&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;All runs utilized the continuous ingest suite that ships with Accumulo (a
standard method to measure performance in Accumulo).  It generates random 
graph data and inserts it into Accumulo, creating
a long linked list of entries.  Part 1 was run with just continuous ingest.&lt;br /&gt;
Based on the test results, there was a measurable performance impact as each additional security configuration was put in place.&lt;/p&gt;

&lt;h2 id=&quot;methodology&quot;&gt;Methodology&lt;/h2&gt;

&lt;p&gt;We ran 5 tests, one for each security configuration.  Each iteration of each test inserted 2 billion entries.  Batch writers were configured with 500K max mem 
to artificially inflate the overall write overhead. This was performed on a
small cluster on AWS.&lt;/p&gt;

&lt;p&gt;Each test used one of the following security configurations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;No security - Default&lt;/li&gt;
  &lt;li&gt;Two way SSL&lt;/li&gt;
  &lt;li&gt;Kerberos/SASL with auth
    &lt;ul&gt;
      &lt;li&gt;auth is just Kerberos authentication between client and server.  Each end of the RPC definitively knows who the other is.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kerberos/SASL with auth-int
    &lt;ul&gt;
      &lt;li&gt;Builds on auth, also providing message integrity checks of the data going across the wire. You also know that the message you received was not altered.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kerberos/SASL with auth-conf
    &lt;ul&gt;
      &lt;li&gt;Builds on auth-int, also providing confidentiality of the message that was sent to prevent others from reading it (aka wire-encryption).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For each test, five iterations were run to obtain a min, max, and median
time elapsed at each security configuration. After each iteration,
Hadoop, and Zookeeper processes were restarted, Accumulo tables are
wiped clean and tables are recreated. In addition, pagecache, dentries
and inodes are dropped by issuing a ‘3’ command on
/proc/sys/vm/drop_caches to ensure that the OS is not caching things to disk
that might affect the benchmark. The following sequence was performed 
between iterations:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bring down Accumulo&lt;/li&gt;
  &lt;li&gt;Bring down Zookeeper&lt;/li&gt;
  &lt;li&gt;Bring down Hadoop&lt;/li&gt;
  &lt;li&gt;Run sync command&lt;/li&gt;
  &lt;li&gt;Drop OS cache&lt;/li&gt;
  &lt;li&gt;Bring up Hadoop&lt;/li&gt;
  &lt;li&gt;Bring up Zookeeper&lt;/li&gt;
  &lt;li&gt;Bring up Accumulo&lt;/li&gt;
  &lt;li&gt;Drop tables&lt;/li&gt;
  &lt;li&gt;Create tables&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For each iteration, the results were stored, fed into &lt;a href=&quot;https://nationalsecurityagency.github.io/timely/&quot;&gt;Timely&lt;/a&gt;, and viewed with Grafana.
Since the runs were executed sequentially, the start epochs for each run did not align.
To mitigate, the entries for each run were inserted 
with the same relative epoch for convenient comparison in Grafana.&lt;/p&gt;

&lt;p&gt;The table configurations for Accumulo remain the same throughout the
different iterations and security levels. The Accumulo site
configurations differ only due to the different settings for the
security level configurations.&lt;/p&gt;

&lt;h2 id=&quot;environment&quot;&gt;Environment&lt;/h2&gt;

&lt;p&gt;In order to perform the testing, a small AWS cluster was setup using 14
hosts on EC2. Two i2.xlarge instances were used as master nodes and eight
d2.xlarge instances were used for workers. In addition, two c4.4xlarge
instances were used for ingesters, one m4.2xlarge instance was used for
Timely, and one m4.xlarge instance was used for Apache Ambari. A logical
diagram of the setup is depicted below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/201702_security/figure1.png&quot; alt=&quot;&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 1 - Cluster Layout, Roles, and Instance Types on AWS.&lt;/p&gt;

&lt;p&gt;The types of nodes and their function are given below:&lt;/p&gt;

&lt;table id=&quot;instance_types&quot; class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Node Type&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;AWS EC2 Type&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;EC2 Type Details&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Quantity&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Ingest Nodes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;c4.4xlarge&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;16 core, 30 GB RAM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worker Node&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;d2.xlarge&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4 cores, 30.5 GB RAM, 3x2T GB HD&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Master Node&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;i2.xlarge&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4 cores, 30.5 GB RAM, 1x800GB SSD&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Admin Node&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;m4.xlarge&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4 cores, 16 GB RAM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Timely Node&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;m4.2xlarge&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8 cores, 32 GB RAM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Table 1 – AWS Instance Types, Role, Details, and Quantities&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;The median, max, and min of the milliseconds elapsed
time of all iterations for each test is displayed below. The percentage change
columns compare the Median, Max, and Min respectively from the no
security level to each security configuration (e.g. no security Median
vs. auth-int Median, no security Max vs. auth-int Max).&lt;/p&gt;

&lt;table id=&quot;results&quot; class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Security Level&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Median&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Standard Deviation&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Max&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Min&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;% Change (nosec Median vs. Median)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;% Change (nosec Max vs. Max)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;% Change (nosec Min vs. Min)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Delta from Previous Level (Median)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;no security&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7829394&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;139340&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8143035&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7764309&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ssl&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8292760&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;87012&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8464060&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8204955&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.92%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.94%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.68%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.92%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;auth&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8859552&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;134109&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9047971&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8657618&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13.16%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.11%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.51%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.83%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;auth-int&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9500737&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;155968&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9753424&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9282371&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.34%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.78%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.55%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.24%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;auth-conf&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9479635&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;170823&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9776580&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9282189&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.08%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20.06%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.55%&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-0.22%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Table 2 – Summarized Time Elapsed for Each Security Level&lt;/p&gt;

&lt;h2 id=&quot;plots&quot;&gt;Plots&lt;/h2&gt;

&lt;p&gt;Below are some snapshots of *stats.out elements via Grafana that were inserted
into Timely with the same relative start time.  Each graph represents a field 
in the output generated by &lt;a href=&quot;https://github.com/apache/accumulo/blob/1.7/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousStatsCollector.java&quot;&gt;ContinuousStatsCollector&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;tablerecshttpsgithubcomapacheaccumuloblob17coresrcmainjavaorgapacheaccumulocoremasterthrifttableinfojaval73&quot;&gt;&lt;a href=&quot;https://github.com/apache/accumulo/blob/1.7/core/src/main/java/org/apache/accumulo/core/master/thrift/TableInfo.java#L73&quot;&gt;TABLE_RECS&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;(Number of records in the continuous ingest table.  Down sample=1m, aggregate=avg)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/blog/201702_security/tableRecs.png&quot;&gt;&lt;img src=&quot;/images/blog/201702_security/tableRecs.png&quot; alt=&quot;&quot; width=&quot;800px&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;totalingesthttpsgithubcomapacheaccumuloblob17coresrcmainjavaorgapacheaccumulocoremasterthrifttableinfojaval77&quot;&gt;&lt;a href=&quot;https://github.com/apache/accumulo/blob/1.7/core/src/main/java/org/apache/accumulo/core/master/thrift/TableInfo.java#L77&quot;&gt;TOTAL_INGEST&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;(Ingest rate for Accumulo instance.  Down sample=5m, aggregate=avg)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/blog/201702_security/totalIngest.png&quot;&gt;&lt;img src=&quot;/images/blog/201702_security/totalIngest.png&quot; alt=&quot;&quot; width=&quot;800px&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;avgfilestablethttpsgithubcomapacheaccumuloblob17coresrcmainjavaorgapacheaccumulocoreutilstatjaval63&quot;&gt;&lt;a href=&quot;https://github.com/apache/accumulo/blob/1.7/core/src/main/java/org/apache/accumulo/core/util/Stat.java#L63&quot;&gt;AVG_FILES/TABLET&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;(Average number of files per Accumulo tablet.  Down sample=1m, aggregate=avg)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/blog/201702_security/avgFilesTab.png&quot;&gt;&lt;img src=&quot;/images/blog/201702_security/avgFilesTab.png&quot; alt=&quot;&quot; width=&quot;800px&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;accumulofileshttpsgithubcomapacheaccumuloblob17testsrcmainjavaorgapacheaccumulotestcontinuouscontinuousstatscollectorjaval127&quot;&gt;&lt;a href=&quot;https://github.com/apache/accumulo/blob/1.7/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousStatsCollector.java#L127&quot;&gt;ACCUMULO_FILES&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;(Total number of files for Accumulo.  Down sample=1m, aggregate=avg)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/blog/201702_security/accumuloFiles.png&quot;&gt;&lt;img src=&quot;/images/blog/201702_security/accumuloFiles.png&quot; alt=&quot;&quot; width=&quot;800px&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As can be seen in the plots above, the different security settings have 
relatively consistent, discernable median run characteristics.  The big
dip in each TOTAL_INGEST coincides with a large number of major
compactions, a rate decrease for TABLE_RECS, and a decrease in 
AVG_FILES/TABLET.&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;/h2&gt;

&lt;p&gt;The biggest performance 
hits to run duration median (compared to default security) were ~21% for 
auth-int and auth-conf.  Interesting to note that SSL’s median run duration was 
lower than all SASL configs and that auth-conf’s was lower than auth-int. 
Initial  speculation for these oddities revolved around the 
&lt;a href=&quot;https://github.com/m1ch1/mapkeeper/wiki/Thrift-Java-Servers-Compared&quot;&gt;Thrift server&lt;/a&gt; 
implementations, but the Thrift differences will not explain the auth-conf/int 
disparity since both utilize TThreadPoolServer.  It was certainly unexpected that the 
addition of wire encryption would yield a faster median run duration.  This result 
prompted, as a sanity check, sniffing the net traffic (in a contrived example 
not during a timed run) in both auth-conf and auth-int to ensure that the message 
contents were actually obfuscated in auth-conf (they were) and not obfuscated in 
auth-int (they weren’t).&lt;/p&gt;

&lt;h2 id=&quot;future-work&quot;&gt;Future Work&lt;/h2&gt;

&lt;p&gt;Part 2 of this series will consist of the same continuous ingest loads and 
configurations with the addition of a query load on the system.&lt;/p&gt;

</description>
        <pubDate>Mon, 06 Mar 2017 00:00:00 -0500</pubDate>
        <link>https://accumulo.apache.org/blog/2017/03/06/security-performance-implications.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2017/03/06/security-performance-implications.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 1.8.1</title>
        <description>&lt;p&gt;Apache Accumulo 1.8.1 is a maintenance release on the 1.8 version branch. This
release contains changes from more then 40 issues, comprised of bug-fixes,
performance improvements, build quality improvements, and more. See
&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12312121&amp;amp;version=12335830&quot;&gt;JIRA&lt;/a&gt; for a complete list.&lt;/p&gt;

&lt;p&gt;Below are resources for this release:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/1.8/accumulo_user_manual.html&quot;&gt;User Manual&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.8/apidocs&quot;&gt;Javadocs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.8/examples&quot;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the context of Accumulo’s &lt;a href=&quot;http://semver.org&quot;&gt;Semantic Versioning&lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/blob/rel/1.8.1/README.md#api&quot;&gt;guidelines&lt;/a&gt;,
this is a “minor version”. This means that new APIs have been created, some
deprecations may have been added, but no deprecated APIs have been removed.
Code written against 1.7.x should work against 1.8.0 – binary compatibility
has been preserved with one exception of an already-deprecated Mock Accumulo
utility class. As always, the Accumulo developers take API compatibility
very seriously and have invested much time to ensure that we meet the promises set forth to our users.&lt;/p&gt;

&lt;h2 id=&quot;major-changes&quot;&gt;Major Changes&lt;/h2&gt;

&lt;h3 id=&quot;problem-with-scans-right-after-minor-compaction&quot;&gt;Problem with scans right after minor compaction&lt;/h3&gt;

&lt;p&gt;A bug was found when 2 or more concurrent scans run on a tablet that
has just undergone minor compaction. The minor compaction thread
writes the in-memory map to a local temporary rfile and tries to
switch the current iterators to use it instead of the native map. The
iterator code in the scan thread may also switch itself to use the local
temporary rfile it if notices it before the minor compaction threads
performs the switch. The bug happened shortly after the switch when
one of the iterator threads will get a NegativeArraySizeException.
See &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4483&quot;&gt;ACCUMULO-4483&lt;/a&gt; for more info.&lt;/p&gt;

&lt;h3 id=&quot;tablet-server-performance-improvement&quot;&gt;Tablet Server Performance Improvement&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4458&quot;&gt;ACCUMULO-4458&lt;/a&gt; mitigated some contention on the Hadoop 
configuration instance backing the XML configs read for SiteConfiguration.&lt;br /&gt;
This should improve overall Tablet Server performance.&lt;/p&gt;

&lt;h3 id=&quot;synchronization-issue-with-deep-copies-of-sources&quot;&gt;Synchronization issue with deep copies of sources&lt;/h3&gt;

&lt;p&gt;Deep copies of iterator sources were not thread safe and threw
exceptions, mostly down in the ZlibDecompressor library.  The real bug
was in the BoundedRangeFileInputStream.  The read() method
synchronizes on the underlying FSDataInputStream, however the
available() method did not.   See &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4391&quot;&gt;ACCUMULO-4391&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;system-permission-bug-in-thrift-proxy&quot;&gt;System permission bug in Thrift Proxy&lt;/h3&gt;

&lt;p&gt;The Accumulo Proxy lacked support for the following system permissions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;System.CREATE_NAMESPACE&lt;/li&gt;
  &lt;li&gt;System.DROP_NAMESPACE&lt;/li&gt;
  &lt;li&gt;System.ALTER_NAMESPACE&lt;/li&gt;
  &lt;li&gt;System.OBTAIN_DELEGATION_TOKEN&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ticket is &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4519&quot;&gt;ACCUMULO-4519&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;shell-compaction-file-selection-options-can-block&quot;&gt;Shell compaction file selection options can block&lt;/h3&gt;

&lt;p&gt;The block happens when the tablet lock is held.  The tablet lock is
meant to protect changes to the tablets internal metadata, and
blocking operations should not occur while this lock is held.  The
compaction command has options to select files based on some
criteria, some of which required blocking operations.  This issue is
fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4572&quot;&gt;ACCUMULO-4572&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;hostregextableloadbalancer-used-stale-information&quot;&gt;HostRegexTableLoadBalancer used stale information&lt;/h3&gt;

&lt;p&gt;The HostRegexTableLoadBalander maintains an internal mapping of tablet
server pools and tablet server status. It was updated at a
configurable interval initially as an optimization. Unfortunately it
had the negative side effect of providing the assignment and balance
operations with stale information.  This lead to a constant shuffling
of tablets.  The configuration property was removed so that
assign/balance methods get updated information every time.  See
&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4576&quot;&gt;ACCUMULO-4576&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;modify-tableoperations-online-to-check-for-table-state&quot;&gt;Modify TableOperations online to check for table state&lt;/h3&gt;

&lt;p&gt;The table operations online operation executes as a fate
operation. If a transaction lock for the table is currently held,
this operation will block even if no action is needed. 
&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4574&quot;&gt;ACCUMULO-4574&lt;/a&gt; changes the behavior of the online
operation to a NOOP if the table is already in the requested state.
This returns immediately without queuing a fate operation.&lt;/p&gt;

&lt;h2 id=&quot;other-notable-changes&quot;&gt;Other Notable Changes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4488&quot;&gt;ACCUMULO-4488&lt;/a&gt; Fix gap in user manual on Kerberos for clients&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-2724&quot;&gt;ACCUMULO-2724&lt;/a&gt; CollectTabletStats had multiple -t parameter&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4431&quot;&gt;ACCUMULO-4431&lt;/a&gt; Log what random is chosen for a tserver.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4494&quot;&gt;ACCUMULO-4494&lt;/a&gt; Include column family seeks in the Iterator Test Harness&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4549&quot;&gt;ACCUMULO-4549&lt;/a&gt; Remove duplicate init functions in TabletBalancer&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4467&quot;&gt;ACCUMULO-4467&lt;/a&gt; Random Walk broken because of unmet dependency on commons-math&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4578&quot;&gt;ACCUMULO-4578&lt;/a&gt; Cancel compaction FATE operation does not release namespace lock&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4505&quot;&gt;ACCUMULO-4505&lt;/a&gt; Shell still reads accumulo-site.xml when using Zookeeper CLI options&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4535&quot;&gt;ACCUMULO-4535&lt;/a&gt; HostRegexTableLoadBalancer fails with NullPointerException&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4575&quot;&gt;ACCUMULO-4575&lt;/a&gt; Concurrent table delete operations leave orphan fate transaction locks&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;upgrading&quot;&gt;Upgrading&lt;/h2&gt;

&lt;p&gt;Upgrades from 1.7 to 1.8 are possible with little effort as no changes were made at the data layer and RPC changes
were made in a backwards-compatible way. The recommended way is to stop Accumulo 1.7, perform the Accumulo upgrade to
1.8, and then start 1.8. Like previous versions, after 1.8 is started on a 1.7 instance, a one-time upgrade will
happen by the Master which will prevent a downgrade back to 1.7. Upgrades are still one way. Upgrades from versions
prior to 1.7 to 1.8 should follow the below path to 1.7 and then perform the upgrade to 1.8 – direct upgrades to 1.8
for versions other than 1.7 are untested.&lt;/p&gt;

&lt;p&gt;Existing configuration files from 1.7 should be compared against the examples provided in 1.8. The 1.7 configuration
files should all function with 1.8 code, but you will likely want to include changes found in the 
&lt;a href=&quot;/release/accumulo-1.8.0/&quot;&gt;1.8.0 release notes&lt;/a&gt; and these release notes for 1.8.1.&lt;/p&gt;

&lt;p&gt;For upgrades from prior to 1.7, follow the upgrade instructions to 1.7 first.&lt;/p&gt;

&lt;h2 id=&quot;testing&quot;&gt;Testing&lt;/h2&gt;

&lt;p&gt;Each unit and functional test only runs on a single node, while the RandomWalk
and Continuous Ingest tests run on any number of nodes. &lt;em&gt;Agitation&lt;/em&gt; refers to
randomly restarting Accumulo processes and Hadoop Datanode processes, and, in
HDFS High-Availability instances, forcing NameNode failover.&lt;/p&gt;

&lt;table id=&quot;release_notes_testing&quot; class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;OS/Environment&lt;/th&gt;
      &lt;th&gt;Hadoop&lt;/th&gt;
      &lt;th&gt;Nodes&lt;/th&gt;
      &lt;th&gt;ZooKeeper&lt;/th&gt;
      &lt;th&gt;HDFS HA&lt;/th&gt;
      &lt;th&gt;Tests&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS7/openJDK1.8.0_121/EC2; 1 m3.xlarge leader, 8 d2.xlarge workers&lt;/td&gt;
      &lt;td&gt;2.7.3&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;3.4.9&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;24 HR Continuous Ingest without Agitation.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS7/openJDK1.8.0_121/EC2; 1 m3.xlarge leader, 8 d2.xlarge workers&lt;/td&gt;
      &lt;td&gt;2.7.3&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;3.4.9&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;24 HR Continuous Ingest with Agitation.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</description>
        <pubDate>Sun, 26 Feb 2017 00:00:00 -0500</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-1.8.1/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-1.8.1/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>Running Accumulo on Fedora 25</title>
        <description>&lt;p&gt;Apache Accumulo has been available in &lt;a href=&quot;https://getfedora.org/&quot;&gt;Fedora&lt;/a&gt; since F20. Recently, the Fedora
packages have been updated to Accumulo version &lt;code class=&quot;highlighter-rouge&quot;&gt;1.6.6&lt;/code&gt; and have made some
improvements to the default configuration and launch scripts to provide a good
out-of-box experience. This post will discuss the basic setup procedures for
running Accumulo in the latest version, &lt;code class=&quot;highlighter-rouge&quot;&gt;Fedora 25&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;prepare-the-system&quot;&gt;Prepare the system&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Before you start, be sure you’ve got plenty of free disk space.
Otherwise, you could run into this &lt;a href=&quot;https://bugzilla.redhat.com/show_bug.cgi?id=1404888&quot;&gt;bug&lt;/a&gt; or see other problems.&lt;/p&gt;

&lt;p&gt;These instructions will assume you’re using Fedora 25, fully up-to-date (&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo
dnf --refresh upgrade&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&quot;install-packages&quot;&gt;Install packages&lt;/h3&gt;

&lt;p&gt;Fedora provides a meta-package to install Accumulo and all of its dependencies.
It’s a good idea to install the JDK, so you’ll have access to the &lt;code class=&quot;highlighter-rouge&quot;&gt;jps&lt;/code&gt;
command, and &lt;code class=&quot;highlighter-rouge&quot;&gt;tuned&lt;/code&gt; for setting system performance tuning parameters from a
profile. It’s also a good idea to ensure the optional hadoop native libraries
are installed, and you have a good editor (replace &lt;code class=&quot;highlighter-rouge&quot;&gt;vim&lt;/code&gt; with your preferred
editor):&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo dnf install accumulo java-1.8.0-openjdk-devel tuned vim hadoop-common-native
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It is possible to install only a specific Accumulo service. For the single node
setup, almost everything is needed. For the multi-node setup, it might make
more sense to be selective about which you choose to install on each node (for
example, to only install &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo-tserver&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&quot;set-up-tuned&quot;&gt;Set up tuned&lt;/h3&gt;

&lt;p&gt;(Optional) &lt;code class=&quot;highlighter-rouge&quot;&gt;tuned&lt;/code&gt; can optimize your server settings, adjusting things like
your &lt;code class=&quot;highlighter-rouge&quot;&gt;vm.swappiness&lt;/code&gt;. To set up &lt;code class=&quot;highlighter-rouge&quot;&gt;tuned&lt;/code&gt;, do:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl start tuned.service     &lt;span class=&quot;c&quot;&gt;# start service&lt;/span&gt;
sudo tuned-adm profile network-latency &lt;span class=&quot;c&quot;&gt;# pick a good profile&lt;/span&gt;
sudo tuned-adm active                  &lt;span class=&quot;c&quot;&gt;# verify the selected profile&lt;/span&gt;
sudo systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;tuned.service    &lt;span class=&quot;c&quot;&gt;# auto-start on reboots&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;set-up-zookeeper&quot;&gt;Set up ZooKeeper&lt;/h3&gt;

&lt;p&gt;You’ll need to set up ZooKeeper, regardless of whether you’ll be running a
single node or many. So, let’s create its configuration file (the defaults are
fine):&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo cp /etc/zookeeper/zoo_sample.cfg /etc/zookeeper/zoo.cfg
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now, let’s start ZooKeeper (and set it to run on reboot):&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl start zookeeper.service
sudo systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;zookeeper.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Note that the default port for ZooKeeper is &lt;code class=&quot;highlighter-rouge&quot;&gt;2181&lt;/code&gt;. Remember the hostname of
the node where ZooKeeper is running, referred to as &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;zk-dns-name&amp;gt;&lt;/code&gt; later.&lt;/p&gt;

&lt;h2 id=&quot;running-a-single-node&quot;&gt;Running a single node&lt;/h2&gt;

&lt;h3 id=&quot;configure-accumulo&quot;&gt;Configure Accumulo&lt;/h3&gt;

&lt;p&gt;To run on a single node, you don’t need to run HDFS. Accumulo can use the local
filesystem as a volume instead. By default, it uses &lt;code class=&quot;highlighter-rouge&quot;&gt;/tmp/accumulo&lt;/code&gt;. Let’s
change that to something which will survive a reboot:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vim /etc/accumulo/accumulo-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Change the value of the &lt;code class=&quot;highlighter-rouge&quot;&gt;instance.volumes&lt;/code&gt; property from &lt;code class=&quot;highlighter-rouge&quot;&gt;file:///tmp/accumulo&lt;/code&gt;
to &lt;code class=&quot;highlighter-rouge&quot;&gt;file:///var/tmp/accumulo&lt;/code&gt; in the configuration file (or another preferred
location).&lt;/p&gt;

&lt;p&gt;While you are editing the Accumulo configuration file, you should also change
the default &lt;code class=&quot;highlighter-rouge&quot;&gt;instance.secret&lt;/code&gt; from &lt;code class=&quot;highlighter-rouge&quot;&gt;DEFAULT&lt;/code&gt; to something else. You can also
change the credentials used by the &lt;code class=&quot;highlighter-rouge&quot;&gt;tracer&lt;/code&gt; service now, too. If you use the
&lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; user, you’ll have to set its password to the same one you’ll use later
when you initialize Accumulo. If you use another user name, you’ll have to
create that user later.&lt;/p&gt;

&lt;h3 id=&quot;configure-hadoop-client&quot;&gt;Configure Hadoop client&lt;/h3&gt;

&lt;p&gt;Hadoop’s default local filesystem handler isn’t very good at ensuring files are
written to disk when services are stopped. So, let’s use a better filesystem
implementation for &lt;code class=&quot;highlighter-rouge&quot;&gt;file://&lt;/code&gt; locations. This implementation may not be as
robust as a full HDFS instance, but it’s more reliable than the default. Even
though you’re not going to be running HDFS, the Hadoop client code used in
Accumulo can still be configured by modifying Hadoop’s configuration file:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vim /etc/hadoop/core-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Add a new property:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.file.impl&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.fs.RawLocalFileSystem&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;initialize-accumulo&quot;&gt;Initialize Accumulo&lt;/h3&gt;

&lt;p&gt;Now, initialize Accumulo. You’ll need to do this as the &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo&lt;/code&gt; user,
because the Accumulo services run as the &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo&lt;/code&gt; user. This user is created
automatically by the RPMs if it doesn’t exist when the RPMs are installed. If
you already have a user and/or group by this name, it will probably not be a
problem, but be aware that this user will have permissions for the server
configuration files. To initialize Accumulo as a specific user, use &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo -u&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo -u accumulo accumulo init
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As expected, this command will fail if ZooKeeper is not running, or if the
destination volume (&lt;code class=&quot;highlighter-rouge&quot;&gt;file:///var/tmp/accumulo&lt;/code&gt;) already exists.&lt;/p&gt;

&lt;h3 id=&quot;start-accumulo-services&quot;&gt;Start Accumulo services&lt;/h3&gt;

&lt;p&gt;Now that Accumulo is initialized, you can start its services:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl start accumulo-&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;master,tserver,gc,tracer,monitor&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Enable the commands to start at boot:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;accumulo-&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;master,tserver,gc,tracer,monitor&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;running-multiple-nodes&quot;&gt;Running multiple nodes&lt;/h2&gt;

&lt;h3 id=&quot;amazon-ec2-setup&quot;&gt;Amazon EC2 setup&lt;/h3&gt;

&lt;p&gt;For a multi-node setup, the authors tested these instructions with a Fedora 25
Cloud AMI on Amazon EC2 with the following characteristics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;us-east-1&lt;/code&gt; availability zone&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ami-e5757bf2&lt;/code&gt; (latest in &lt;code class=&quot;highlighter-rouge&quot;&gt;us-east-1&lt;/code&gt; at time of writing)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HVM&lt;/code&gt; virtualization type&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gp2&lt;/code&gt; disk type&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;64GB EBS&lt;/code&gt; root volume (no additional storage)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;m4.large&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;m4.xlarge&lt;/code&gt; instance types (tested on both)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;3&lt;/code&gt; nodes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this setup, you should have a name service configured properly. For
convenience, we used the EC2 provided internal DNS, with internal IP addresses.
Make sure the nodes can communicate with each other using these names. If
you’re using EC2, this means making sure they are in the same security group,
and the security group has an inbound rule for “All traffic” with the source
set to itself (&lt;code class=&quot;highlighter-rouge&quot;&gt;sg-xxxxxxxx&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;The default user is &lt;code class=&quot;highlighter-rouge&quot;&gt;fedora&lt;/code&gt; for the Fedora Cloud AMIs. For the best
experience, don’t forget to make sure they are fully up-to-date (&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo dnf
--refresh upgrade&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&quot;configure-and-run-hadoop&quot;&gt;Configure and run Hadoop&lt;/h3&gt;

&lt;p&gt;Configuring HDFS is the primary difference between the single and multi-node
setup. For both Hadoop and Accumulo, you can edit the configuration files on
one machine, and copy them to the others.&lt;/p&gt;

&lt;p&gt;Pick a server to be the NameNode and identify its DNS name,
(&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;namenode-dns-name&amp;gt;&lt;/code&gt;). Edit Hadoop’s configuration to set the default
filesystem name to this location:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vim /etc/hadoop/core-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Set the value for the property &lt;code class=&quot;highlighter-rouge&quot;&gt;fs.default.name&lt;/code&gt; to
&lt;code class=&quot;highlighter-rouge&quot;&gt;hdfs://&amp;lt;namenode-dns-name&amp;gt;:8020&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Distribute copies of the changed configuration files to each node.&lt;/p&gt;

&lt;p&gt;Now, format the NameNode. You’ll need to do this as the &lt;code class=&quot;highlighter-rouge&quot;&gt;hdfs&lt;/code&gt; user on the
NameNode instance:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo -u hdfs hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;On the NameNode, start the NameNode service and enable it on reboot:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl start hadoop-namenode.service
sudo systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;hadoop-namenode.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;On each DataNode, start the DataNode service:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl start hadoop-datanode.service
sudo systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;hadoop-datanode.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;configure-and-run-accumulo&quot;&gt;Configure and run Accumulo&lt;/h3&gt;

&lt;p&gt;Update Accumulo’s configuration to use this HDFS filesystem:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vim /etc/accumulo/accumulo-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Change the value of the &lt;code class=&quot;highlighter-rouge&quot;&gt;instance.volumes&lt;/code&gt; to
&lt;code class=&quot;highlighter-rouge&quot;&gt;hdfs://&amp;lt;namenode-dns-name&amp;gt;:8020/accumulo&lt;/code&gt; in the configuration file. Don’t
forget to also change the default &lt;code class=&quot;highlighter-rouge&quot;&gt;instance.secret&lt;/code&gt; and the trace user’s
credentials, if necessary. Also, since you will have multiple nodes, you cannot
use &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:2181&lt;/code&gt; for ZooKeeper, so set &lt;code class=&quot;highlighter-rouge&quot;&gt;instance.zookeeper.host&lt;/code&gt; to
&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;zk-dns-name&amp;gt;:2181&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Distribute copies of the changed configuration files to each node.&lt;/p&gt;

&lt;p&gt;With HDFS now running, make sure Accumulo has permission to create its
directory in HDFS, and initialize Accumulo:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo -u hdfs hdfs dfs -chmod 777 /
sudo -u accumulo accumulo init
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After Accumulo has created its directory structure, you can change the
permissions for the root back to what they were:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo -u hdfs hdfs dfs -chmod 755 /
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Note: we only choose to do the above because this is a developer/testing
environment. Temporarily changing ownership of HDFS is not recommended for
the root of HDFS.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now, you can start Accumulo.&lt;/p&gt;

&lt;p&gt;On the NameNode, start all the Accumulo services and enable on reboot:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl start accumulo-&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;master,tserver,gc,tracer,monitor&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;.service
sudo systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;accumulo-&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;master,tserver,gc,tracer,monitor&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;On each DataNode, start just the &lt;code class=&quot;highlighter-rouge&quot;&gt;tserver&lt;/code&gt; and enable it on reboot:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl start accumulo-tserver.service
sudo systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;accumulo-tserver.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;watching-and-using-accumulo&quot;&gt;Watching and using Accumulo&lt;/h2&gt;

&lt;h3 id=&quot;run-the-shell&quot;&gt;Run the shell&lt;/h3&gt;

&lt;p&gt;Run a shell as Accumulo’s root user (the instance name and root password are
the ones you selected during the initialize step above:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;accumulo shell -u root -zh &amp;lt;zk-dns-name&amp;gt;:2181 -zi &amp;lt;instanceName&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;view-the-monitor-pages&quot;&gt;View the monitor pages&lt;/h3&gt;

&lt;p&gt;You should also be able to view the NameNode monitor page and the Accumulo
monitor pages. If you are running this in EC2, you can view these over an SSH
tunnel using the NameNode’s public IP address. If you didn’t give this node a
public IP address, you can allocate one in EC2 and associate it with this node:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh -L50070:localhost:50070 -L50095:localhost:50095 &amp;lt;user&amp;gt;@&amp;lt;host&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;user&amp;gt;&lt;/code&gt; with your username (probably &lt;code class=&quot;highlighter-rouge&quot;&gt;fedora&lt;/code&gt; if using the Fedora
AMI), and &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;host&amp;gt;&lt;/code&gt; with the public IP or hostname for your EC2 instance. Now,
in your local browser, you should be able to navigate to these addresses in
your localhost: &lt;a href=&quot;http://localhost:50070&quot;&gt;Hadoop monitor (http://localhost:50070)&lt;/a&gt; and &lt;a href=&quot;http://localhost:50095&quot;&gt;Accumulo
monitor (http://localhost:50095)&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;debugging-commands&quot;&gt;Debugging commands&lt;/h2&gt;

&lt;p&gt;Check the status of a service:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl status &amp;lt;ServiceName&amp;gt;.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Check running Java processes:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo jps -ml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Check the system logs for a specific service within the last 10 minutes:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo journalctl -u &amp;lt;ServiceName&amp;gt; --since &lt;span class=&quot;s1&quot;&gt;'10 minutes ago'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Check listening ports:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo netstat -tlnp
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Check DNS name for a given IP address:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;getent hosts &amp;lt;ipaddress&amp;gt; &lt;span class=&quot;c&quot;&gt;# OR&lt;/span&gt;
hostname -A
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Perform forward and reverse DNS lookups:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo dnf install &lt;span class=&quot;nb&quot;&gt;bind&lt;/span&gt;-utils
dig +short &amp;lt;hostname&amp;gt;     &lt;span class=&quot;c&quot;&gt;# forward DNS lookup&lt;/span&gt;
dig +short -x &amp;lt;ipaddress&amp;gt; &lt;span class=&quot;c&quot;&gt;# reverse DNS lookup&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Find the instance ID for your instance name:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;zkCli.sh -server &amp;lt;host&amp;gt;:2181     &lt;span class=&quot;c&quot;&gt;# replace &amp;lt;host&amp;gt; with your ZooKeeper server DNS name&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;get /accumulo/instances/&amp;lt;name&amp;gt; &lt;span class=&quot;c&quot;&gt;# replace &amp;lt;name&amp;gt; with your instance name&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;quit
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;If the NameNode is listening on the loopback address, you’ll probably need to
restart the service manually, as well as any Accumulo services which failed.
This is a &lt;a href=&quot;https://bugzilla.redhat.com/show_bug.cgi?id=1406165&quot;&gt;known issue with Hadoop&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl restart hadoop-namenode.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Some helpful rpm commands:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rpm -q -i &amp;lt;installed-package-name&amp;gt;              &lt;span class=&quot;c&quot;&gt;# to see info about an installed package&lt;/span&gt;
rpm -q -i -p &amp;lt;rpm-file-name&amp;gt;                    &lt;span class=&quot;c&quot;&gt;# to see info about an rpm file&lt;/span&gt;
rpm -q --provides &amp;lt;installed-package-name&amp;gt;      &lt;span class=&quot;c&quot;&gt;# see what a package provides&lt;/span&gt;
rpm -q --requires &amp;lt;installed-package-name&amp;gt;      &lt;span class=&quot;c&quot;&gt;# see what a package requires&lt;/span&gt;
rpm -q -l &amp;lt;installed-package-name&amp;gt;              &lt;span class=&quot;c&quot;&gt;# list package files&lt;/span&gt;
rpm -q --whatprovides &amp;lt;file&amp;gt;                    &lt;span class=&quot;c&quot;&gt;# find rpm which owns &amp;lt;file&amp;gt;&lt;/span&gt;
rpm -q --whatrequires &lt;span class=&quot;s1&quot;&gt;'mvn(groupId:artifactId)'&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# find rpm which requires maven coords&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;helping-out&quot;&gt;Helping out&lt;/h2&gt;

&lt;p&gt;Feel free to get involved with the &lt;a href=&quot;https://fedoraproject.org/wiki/Join_the_package_collection_maintainers&quot;&gt;Fedora&lt;/a&gt; or &lt;a href=&quot;https://fedoraproject.org/wiki/EPEL&quot;&gt;Fedora EPEL&lt;/a&gt;
(for RHEL/CentOS users) packaging. Contact the Fedora &lt;a href=&quot;https://admin.fedoraproject.org/pkgdb/package/rpms/accumulo/&quot;&gt;maintainers&lt;/a&gt; (user &lt;code class=&quot;highlighter-rouge&quot;&gt;at&lt;/code&gt;
fedoraproject &lt;code class=&quot;highlighter-rouge&quot;&gt;dot&lt;/code&gt; org) for the Accumulo packages to see how you can help
patching bugs, adapting the upstream packages to the Fedora packaging
standards, testing updates, maintaining dependency packages, and more.&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Dec 2016 00:00:00 -0500</pubDate>
        <link>https://accumulo.apache.org/blog/2016/12/19/running-on-fedora-25.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2016/12/19/running-on-fedora-25.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Simpler scripts and configuration coming in Accumulo 2.0.0</title>
        <description>&lt;p&gt;For the upcoming 2.0.0 release, Accumulo’s scripts and configuration &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4490&quot;&gt;were refactored&lt;/a&gt;
to make Accumulo easier to use. While Accumulo’s documentation (i.e. the user
manual and &lt;a href=&quot;https://github.com/apache/accumulo/blob/master/INSTALL.md&quot;&gt;INSTALL.md&lt;/a&gt;) were updated with any changes that were made, this blog post provides
a summary of the changes.&lt;/p&gt;

&lt;h3 id=&quot;fewer-scripts&quot;&gt;Fewer scripts&lt;/h3&gt;

&lt;p&gt;Before 2.0.0, the &lt;code class=&quot;highlighter-rouge&quot;&gt;bin/&lt;/code&gt; directory of Accumulo’s binary tarball contained about 20 scripts:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;ls accumulo-1.8.0/bin/
accumulo             build_native_library.sh  generate_monitor_certificate.sh  start-here.sh    stop-server.sh
accumulo_watcher.sh  check-slaves             LogForwarder.sh                  start-server.sh  tdown.sh
bootstrap_config.sh  config-server.sh         start-all.sh                     stop-all.sh      tool.sh
bootstrap_hdfs.sh    config.sh                start-daemon.sh                  stop-here.sh     tup.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The number of scripts made it difficult to know which scripts to use.  If you added the &lt;code class=&quot;highlighter-rouge&quot;&gt;bin/&lt;/code&gt; directory to your 
&lt;code class=&quot;highlighter-rouge&quot;&gt;PATH&lt;/code&gt;, it could add unecessary commands to your PATH or cause commands to be overriden due generic names
(like ‘start-all.sh’). The number of scripts were reduced by removing scripts that are no longer used and combining
scripts with similiar functionality.&lt;/p&gt;

&lt;p&gt;Starting with 2.0.0, Accumulo will only have 4 scripts in its &lt;code class=&quot;highlighter-rouge&quot;&gt;bin/&lt;/code&gt; directory:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;ls accumulo-2.0.0/bin/
accumulo  accumulo-cluster  accumulo-service  accumulo-util
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Below are some notes on this change:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The ‘accumulo’ script was mostly left alone except for improved usage.&lt;/li&gt;
  &lt;li&gt;The ‘accumulo-service’ script was created to manage Accumulo processes as services&lt;/li&gt;
  &lt;li&gt;The ‘accumulo-cluster’ command was created to manage Accumulo on cluster and replaces ‘start-all.sh’ and ‘stop-all.sh’.&lt;/li&gt;
  &lt;li&gt;The ‘accumulo-util’ command combines many utility scripts such as ‘build_native_library.sh’, ‘tool.sh’, etc into one script.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;less-configuration&quot;&gt;Less configuration&lt;/h3&gt;

&lt;p&gt;Before 2.0.0, Accumulo’s &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/&lt;/code&gt; directory looked like the following (after creating initial config files
using ‘bootstrap_config.sh’):&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;ls accumulo-1.8.0/conf/
accumulo-env.sh          auditLog.xml  generic_logger.properties            masters                    slaves
accumulo-metrics.xml     client.conf   generic_logger.xml                   monitor                    templates
accumulo.policy.example  examples      hadoop-metrics2-accumulo.properties  monitor_logger.properties  tracers
accumulo-site.xml        gc            log4j.properties                     monitor_logger.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;While all of these files have a purpose, many are only used in rare situations. For Accumulo 2.0, the ‘conf/’
directory now only contains a minimum set of configuration files needed to run Accumulo.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;ls accumulo-2.0.0/conf/
accumulo-env.sh  accumulo-site.xml  client.conf  log4j-monitor.properties  log4j.properties  log4j-service.properties  templates
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The Accumulo tarball does contain host files (i.e ‘tservers’, ‘monitor’, etc) by default as these files are only required by
the ‘accumulo-cluster’ command. However, the script has a command to generate them.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;./bin/accumulo-cluster create-config
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Any less common configuration files can still be found in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/templates&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;better-usage&quot;&gt;Better usage&lt;/h3&gt;

&lt;p&gt;Before 2.0.0, the ‘accumulo’ command had a limited usage:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./accumulo-1.8.0/bin/accumulo
accumulo admin | check-server-config | classpath | create-token | gc | help | info | init | jar &amp;lt;jar&amp;gt; [&amp;lt;main class&amp;gt;] args |
  login-info | master | minicluster | monitor | proxy | rfile-info | shell | tracer | tserver | version | zookeeper | &amp;lt;accumulo class&amp;gt; args
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;For 2.0.0, all ‘accumulo’ commands were given a short description and organized into the groups.  Below is
the full usage. It should be noted that usage is limited until the ‘accumulo-env.sh’ configuration file is
created in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/&lt;/code&gt; by the &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo create-config&lt;/code&gt; command.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./accumulo-2.0.0/bin/accumulo help

Usage: accumulo &amp;lt;command&amp;gt; [-h] (&amp;lt;argument&amp;gt; ...)

  -h   Prints usage for specified command

Core Commands:
  init                           Initializes Accumulo
  shell                          Runs Accumulo shell
  classpath                      Prints Accumulo classpath
  version                        Prints Accumulo version
  admin                          Executes administrative commands
  info                           Prints Accumulo cluster info
  help                           Prints usage
  &amp;lt;main class&amp;gt; args              Runs Java &amp;lt;main class&amp;gt; located on Accumulo classpath

Process Commands:
  gc                             Starts Accumulo garbage collector
  master                         Starts Accumulo master
  monitor                        Starts Accumulo monitor
  minicluster                    Starts Accumulo minicluster
  proxy                          Starts Accumulo proxy
  tserver                        Starts Accumulo tablet server
  tracer                         Starts Accumulo tracer
  zookeeper                      Starts Apache Zookeeper instance

Advanced Commands:
  check-server-config            Checks server config
  create-token                   Creates authentication token
  login-info                     Prints Accumulo login info
  rfile-info                     Prints rfile info
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The new ‘accumulo-service’ and ‘accumulo-cluster’ commands also have informative usage.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./accumulo-2.0.0/bin/accumulo-service 

Usage: accumulo-service &amp;lt;service&amp;gt; &amp;lt;command&amp;gt;

Services:
  gc          Accumulo garbage collector
  monitor     Accumulo monitor
  master      Accumulo master
  tserver     Accumulo tserver
  tracer      Accumulo tracter

Commands:
  start       Starts service
  stop        Stops service
  kill        Kills service

$ ./accumulo-2.0.0/bin/accumulo-cluster 

Usage: accumulo-cluster &amp;lt;command&amp;gt; (&amp;lt;argument&amp;gt; ...)

Commands:
  create-config       Creates cluster config
  start               Starts Accumulo cluster
  stop                Stops Accumulo cluster
  start-non-tservers  Starts all services except tservers
  start-tservers      Starts all tservers on cluster
  stop-tservers       Stops all tservers on cluster
  start-here          Starts all services on this node
  stop-here           Stops all services on this node
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;This post was updated on March 24, 2017 to reflect changes to Accumulo 2.0&lt;/em&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 16 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://accumulo.apache.org/blog/2016/11/16/simpler-scripts-and-config.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2016/11/16/simpler-scripts-and-config.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Durability Performance Implications</title>
        <description>&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;Accumulo stores recently written data in a sorted in memory map.  Before data is
added to this map, it’s written to an unsorted write ahead log(WAL).  In the
case when a tablet server dies, the recently written data is recovered from the
WAL.&lt;/p&gt;

&lt;p&gt;When data is written to Accumulo the following happens :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Client sends a batch of mutations to a tablet server&lt;/li&gt;
  &lt;li&gt;Tablet server does the following :
    &lt;ul&gt;
      &lt;li&gt;Writes mutation to tablet servers’ WAL&lt;/li&gt;
      &lt;li&gt;Sync or flush tablet servers’ WAL&lt;/li&gt;
      &lt;li&gt;Adds mutations to sorted in memory map of each tablet.&lt;/li&gt;
      &lt;li&gt;Reports success back to client.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The sync/flush step above moves data written to the WAL from memory to disk.
Write ahead logs are stored in HDFS. HDFS supports two ways of forcing data to
disk for an open file : &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;hdfs-syncflush-details&quot;&gt;HDFS Sync/Flush Details&lt;/h2&gt;

&lt;p&gt;When &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt; is called on a WAL, it does not guarantee data is on disk.  It
only guarantees that data is in OS buffers on each datanode and on its way to disk.
As a result calls to &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt; are very fast.  If a WAL is replicated to 3 data
nodes then data may be lost if all three machines reboot or die.  If the datanode
process dies, then data loss will not happen because the data was in OS buffers
waiting to be written to disk.  The machines have to reboot or die for data loss to
occur.&lt;/p&gt;

&lt;p&gt;In order to avoid data loss in the event of reboot, &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; can be called.  This
will ensure data is written to disk on all datanodes before returning.  When
using &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; for the WAL, if Accumulo reports success to a user it means the
data is on disk.  However &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; is much slower than &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt; and the way it’s
implemented exacerbates the problem.  For example &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt; make take 1ms and
&lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; may take 50ms.  This difference will impact writes to Accumulo and can
be mitigated in some situations with larger buffers in Accumulo.&lt;/p&gt;

&lt;p&gt;HDFS keeps checksum data internally by default.  Datanodes store checksum data
in a separate file in the local filesystem.  This means when &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; is called
on a WAL, two files must be synced on each datanode.  Syncing two files doubles
the time. To make matters even worse, when the two files are synced the local
filesystem metadata is also synced.  Depending on the local filesystem and its
configuration, syncing the metadata may or may not take time.  In the worst
case, we need to wait for four sync operations at the local filesystem level on
each datanode. One thing I am not sure about, is if these sync operations occur
in parallel on the replicas on different datanodes.  If anyone can answer this
question, please let us know on the &lt;a href=&quot;/mailing_list&quot;&gt;dev list&lt;/a&gt;. The following pointers show
where sync occurs in the datanode code.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/hadoop/blob/release-2.7.1/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java#L358&quot;&gt;BlockReceiver.flushOrSync()&lt;/a&gt; calls &lt;a href=&quot;https://github.com/apache/hadoop/blob/release-2.7.1/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/ReplicaOutputStreams.java#L78&quot;&gt;ReplicaOutputStreams.syncDataOut()&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/hadoop/blob/release-2.7.1/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/ReplicaOutputStreams.java#L87&quot;&gt;ReplicaOutputStreams.syncChecksumOut()&lt;/a&gt; when &lt;code class=&quot;highlighter-rouge&quot;&gt;isSync&lt;/code&gt; is true.&lt;/li&gt;
  &lt;li&gt;The methods in ReplicaOutputStreams call &lt;a href=&quot;https://docs.oracle.com/javase/8/docs/api/java/nio/channels/FileChannel.html#force-boolean-&quot;&gt;FileChannel.force(true)&lt;/a&gt; which
synchronously flushes data and filesystem metadata.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If files were preallocated (this would avoid syncing local filesystem metadata)
and checksums were stored in-line, then 1 sync could be done instead of 4.&lt;/p&gt;

&lt;h2 id=&quot;configuring-wal-flushsync-in-accumulo-16&quot;&gt;Configuring WAL flush/sync in Accumulo 1.6&lt;/h2&gt;

&lt;p&gt;Accumulo 1.6.0 only supported &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; and this caused &lt;a href=&quot;/release/accumulo-1.6.0#slower-writes-than-previous-accumulo-versions&quot;&gt;performance
problems&lt;/a&gt;.  In order to offer better performance, the option to
configure &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt; was &lt;a href=&quot;/release/accumulo-1.6.1#write-ahead-log-sync-implementation&quot;&gt;added in 1.6.1&lt;/a&gt;.  The
&lt;a href=&quot;/1.6/accumulo_user_manual#_tserver_wal_sync_method&quot;&gt;tserver.wal.sync.method&lt;/a&gt; configuration option was added to support
this feature.  This was a tablet server wide option that applied to everything
written to any table.&lt;/p&gt;

&lt;h2 id=&quot;group-commit&quot;&gt;Group Commit&lt;/h2&gt;

&lt;p&gt;Each Accumulo tablet server has a single WAL.  When multiple clients send
mutations to a tablet server at around the same time, the tablet sever may group
all of this into a single WAL operation.  It will do this instead of writing and
syncing or flushing each client’s mutations to the WAL separately.  Doing this
increase throughput and lowers average latency for clients.&lt;/p&gt;

&lt;h2 id=&quot;configuring-wal-flushsync-in-accumulo-17&quot;&gt;Configuring WAL flush/sync in Accumulo 1.7+&lt;/h2&gt;

&lt;p&gt;Accumulo 1.7.0 introduced &lt;a href=&quot;/1.7/accumulo_user_manual#_table_durability&quot;&gt;table.durability&lt;/a&gt;, a new per table property
for configuring durability.  It also stopped using the &lt;code class=&quot;highlighter-rouge&quot;&gt;tserver.wal.sync.method&lt;/code&gt;
property.  The &lt;code class=&quot;highlighter-rouge&quot;&gt;table.durability&lt;/code&gt; property has the following four legal values.
This property defaults to the most durable option which is &lt;code class=&quot;highlighter-rouge&quot;&gt;sync&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;none&lt;/strong&gt; : Do not write to WAL&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;log&lt;/strong&gt;  : Write to WAL, but do not sync&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;flush&lt;/strong&gt; : Write to WAL and call &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;sync&lt;/strong&gt; : Write to WAL and call &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If multiple writes arrive at around the same time with different durability
settings, then the group commit code will choose the most durable.  This can
cause one tables settings to slow down writes to another table.  Basically, one
table that is set to &lt;code class=&quot;highlighter-rouge&quot;&gt;sync&lt;/code&gt; can impact the entire system.&lt;/p&gt;

&lt;p&gt;In Accumulo 1.6, it was easy to make all writes use &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt; because there was
only one tserver setting.  Getting everything to use &lt;code class=&quot;highlighter-rouge&quot;&gt;flush&lt;/code&gt; in 1.7 and later
can be a little tricky because by default the Accumulo metadata table is set to
use &lt;code class=&quot;highlighter-rouge&quot;&gt;sync&lt;/code&gt;.  The following shell commands show this. The first command sets
&lt;code class=&quot;highlighter-rouge&quot;&gt;table.durability=flush&lt;/code&gt; as a system wide default for all tables.  However, the
metadata table is still set to &lt;code class=&quot;highlighter-rouge&quot;&gt;sync&lt;/code&gt;, because it has a per table override for
that setting.  This override is set when Accumulo is initialized.  To get this
table to use &lt;code class=&quot;highlighter-rouge&quot;&gt;flush&lt;/code&gt;, the per table override must be deleted.  After deleting
those properties, the metadata tables will inherit the system wide setting.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@uno&amp;gt; config -s table.durability=flush
root@uno&amp;gt; createtable foo
root@uno foo&amp;gt; config -t foo -f table.durability
-----------+---------------------+----------------------------------------------
SCOPE      | NAME                | VALUE
-----------+---------------------+----------------------------------------------
default    | table.durability .. | sync
system     |    @override ...... | flush
-----------+---------------------+----------------------------------------------
root@uno&amp;gt; config -t accumulo.metadata -f table.durability
-----------+---------------------+----------------------------------------------
SCOPE      | NAME                | VALUE
-----------+---------------------+----------------------------------------------
default    | table.durability .. | sync
system     |    @override ...... | flush
table      |    @override ...... | sync
-----------+---------------------+----------------------------------------------
root@uno&amp;gt; config -t accumulo.metadata -d table.durability
root@uno&amp;gt; config -t accumulo.metadata -f table.durability
-----------+---------------------+----------------------------------------------
SCOPE      | NAME                | VALUE
-----------+---------------------+----------------------------------------------
default    | table.durability .. | sync
system     |    @override ...... | flush
-----------+---------------------+----------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In short, executing the following commands will make all writes use &lt;code class=&quot;highlighter-rouge&quot;&gt;flush&lt;/code&gt;
(assuming no other tables or namespaces have been specifically set to &lt;code class=&quot;highlighter-rouge&quot;&gt;sync&lt;/code&gt;).&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;config -s table.durability=flush
config -t accumulo.metadata -d table.durability
config -t accumulo.root -d table.durability
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Even with these settings adjusted, minor compactions could still force &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt;
to be called in 1.7.0 and 1.7.1.  This was fixed in 1.7.2 and 1.8.0.  See the
&lt;a href=&quot;/release/accumulo-1.7.2#minor-performance-improvements&quot;&gt;1.7.2 release notes&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4112&quot;&gt;ACCUMULO-4112&lt;/a&gt; for more details.&lt;/p&gt;

&lt;p&gt;In addition to the per table durability setting, a per batch writer durability
setting was also added in 1.7.0.  See
&lt;a href=&quot;/1.8/apidocs/org/apache/accumulo/core/client/BatchWriterConfig.html#setDurability(org.apache.accumulo.core.client.Durability)&quot;&gt;BatchWriterConfig.setDurability(…)&lt;/a&gt;.  This means any client could
potentially cause a &lt;code class=&quot;highlighter-rouge&quot;&gt;hsync&lt;/code&gt; operation to occur, even if the system is
configured to use &lt;code class=&quot;highlighter-rouge&quot;&gt;hflush&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;improving-the-situation&quot;&gt;Improving the situation&lt;/h2&gt;

&lt;p&gt;The more granular durability settings introduced in 1.7.0 can cause some
unexpected problems.  &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4146&quot;&gt;ACCUMULO-4146&lt;/a&gt; suggests one possible way to solve these
problems with Per-durability write ahead logs.&lt;/p&gt;

</description>
        <pubDate>Wed, 02 Nov 2016 13:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/blog/2016/11/02/durability-performance.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2016/11/02/durability-performance.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 1.6.6</title>
        <description>&lt;p&gt;Apache Accumulo 1.6.6 is a maintenance release on the 1.6 version branch. This
release contains changes from more than 40 issues, comprised of bug-fixes,
performance improvements, build quality improvements, and more. See
&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12312121&amp;amp;version=12334846&quot;&gt;JIRA&lt;/a&gt; for a complete list.&lt;/p&gt;

&lt;p&gt;Below are resources for this release:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/1.6/accumulo_user_manual.html&quot;&gt;User Manual&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.6/apidocs&quot;&gt;Javadocs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.6/examples&quot;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Users of any previous 1.6.x release are strongly encouraged to update as soon
as possible to benefit from the improvements with very little concern in change
of underlying functionality.&lt;/p&gt;

&lt;p&gt;As of this release, active development has ceased for the 1.6 release line, so
users should consider upgrading to a newer, actively maintained version when
they can. While the developers may release another 1.6 version to address a
severe issue, there’s a strong possibility that this will be the last 1.6
release. That would also mean that this will be the last Accumulo version to
support Java 6 and Hadoop 1.&lt;/p&gt;

&lt;h2 id=&quot;highlights&quot;&gt;Highlights&lt;/h2&gt;

&lt;h3 id=&quot;write-ahead-logs-can-be-prematurely-deleted&quot;&gt;Write-Ahead Logs can be prematurely deleted&lt;/h3&gt;

&lt;p&gt;There were cases where the Accumulo Garbage Collector may inadvertently delete
a WAL for a tablet server that it has erroneously determined to be down,
causing data loss. This has been corrected. See &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4157&quot;&gt;ACCUMULO-4157&lt;/a&gt;
for additional detail.&lt;/p&gt;

&lt;h3 id=&quot;upgrade-to-commons-vfs-21&quot;&gt;Upgrade to Commons-VFS 2.1&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;UPDATE (20161202)&lt;/strong&gt;: This change was reverted prior to releasing 1.6.6,
because it broke the build with Hadoop 1. Hadoop 1 support was dropped in 1.7.0
and later, so builds were not affected in those branches. It is still possible
to Apache Commons VFS 2.1, but you may need backport the patch. See
&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-3470&quot;&gt;ACCUMULO-3470&lt;/a&gt; for details.&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Upgrading to Apache Commons VFS 2.1 fixes several issues with classloading out
of HDFS. For further detail see &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4146&quot;&gt;ACCUMULO-4146&lt;/a&gt;. Additional
fixes to a potential HDFS class loading deadlock situation were made in
&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4341&quot;&gt;ACCUMULO-4341&lt;/a&gt;.&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&quot;native-map-failed-to-increment-mutation-count-properly&quot;&gt;Native Map failed to increment mutation count properly&lt;/h3&gt;

&lt;p&gt;There was a bug (&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4148&quot;&gt;ACCUMULO-4148&lt;/a&gt;) where multiple put calls with
identical keys and no timestamp would exhibit different behaviour depending on
whether native maps were enabled or not. This behaviour would result in hidden
mutations with native maps, and has been corrected.&lt;/p&gt;

&lt;h3 id=&quot;open-wal-files-could-prevent-datanode-decomission&quot;&gt;Open WAL files could prevent DataNode decomission&lt;/h3&gt;

&lt;p&gt;An improvement was introduced to allow a max age before WAL files would be
automatically rolled. Without a max age, they could stay open for writing
indefinitely, blocking the Hadoop DataNode decomissioning process. For more
information, see &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4004&quot;&gt;ACCUMULO-4004&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;remove-unnecessary-copy-of-cached-rfile-index-blocks&quot;&gt;Remove unnecessary copy of cached RFile index blocks&lt;/h3&gt;

&lt;p&gt;Accumulo maintains an cache for file blocks in-memory as a performance
optimization. This can be done safely because Accumulo RFiles are immutable,
thus their blocks are also immutable. There are two types of these blocks:
index and data blocks. Index blocks refer to the b-tree style index inside of
each Accumulo RFile, while data blocks contain the sorted Key-Value pairs. In
previous versions, when Accumulo extracted an Index block from the in-memory
cache, it would copy the data. &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4164&quot;&gt;ACCUMULO-4164&lt;/a&gt; removes this
unnecessary copy as the contents are immutable and can be passed by reference.
Ensuring that the Index blocks are not copied when accessed from the cache is a
big performance gain at the file-access level.&lt;/p&gt;

&lt;h3 id=&quot;analyze-key-length-to-avoid-choosing-large-keys-for-rfile-index-blocks&quot;&gt;Analyze Key-length to avoid choosing large Keys for RFile Index blocks&lt;/h3&gt;

&lt;p&gt;Accumulo’s RFile index blocks are made up of a Key which exists in the file and
points to that specific location in the corresponding RFile data block. Thus,
the size of the RFile index blocks is largely dominated by the size of the Keys
which are used by the index. &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4314&quot;&gt;ACCUMULO-4314&lt;/a&gt; is an improvement
which uses statistics on the length of the Keys in the Rfile to avoid choosing
Keys for the index whose length is greater than three standard deviations for
the RFile. By choosing smaller Keys for the index, Accumulo can access the
RFile index faster and keep more Index blocks cached in memory. Initial tests
showed that with this change, the RFile index size was nearly cut in half.&lt;/p&gt;

&lt;h3 id=&quot;gson-version-bump&quot;&gt;Gson version bump&lt;/h3&gt;

&lt;p&gt;Due to an &lt;a href=&quot;https://github.com/google/gson/issues/362&quot;&gt;upstream bug with Gson 2.2.2&lt;/a&gt;, we’ve bumped our bundled
dependency (&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4345&quot;&gt;ACCUMULO-4345&lt;/a&gt;) to version 2.2.4. Please take note
of this when you upgrade, if you were using the version shipped with Accumulo,
and were relying on the buggy behavior in the previous version in your own
code.&lt;/p&gt;

&lt;h3 id=&quot;minor-performance-improvements&quot;&gt;Minor performance improvements.&lt;/h3&gt;

&lt;p&gt;A performance issue was identified and corrected
(&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-1755&quot;&gt;ACCUMULO-1755&lt;/a&gt;) where the BatchWriter would block calls to
addMutation while looking up destination tablet server metadata. The writer has
been fixed to allow both operations in parallel.&lt;/p&gt;

&lt;h2 id=&quot;other-notable-changes&quot;&gt;Other Notable Changes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4155&quot;&gt;ACCUMULO-4155&lt;/a&gt; No longer publish javadoc for non-public API
to website. (Still available in javadoc jars in maven)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4334&quot;&gt;ACCUMULO-4334&lt;/a&gt; Ingest rates reported through JMX did not
match rates reported by Monitor.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4335&quot;&gt;ACCUMULO-4335&lt;/a&gt; Error conditions that result in a Halt should
ensure non-zero process exit code.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;testing&quot;&gt;Testing&lt;/h2&gt;

&lt;p&gt;Each unit and functional test only runs on a single node, while the RandomWalk
and Continuous Ingest tests run on any number of nodes. &lt;em&gt;Agitation&lt;/em&gt; refers to
randomly restarting Accumulo processes and Hadoop Datanode processes, and, in
HDFS High-Availability instances, forcing NameNode failover.&lt;/p&gt;

&lt;table id=&quot;release_notes_testing&quot; class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;OS/Environment&lt;/th&gt;
      &lt;th&gt;Hadoop&lt;/th&gt;
      &lt;th&gt;Nodes&lt;/th&gt;
      &lt;th&gt;ZooKeeper&lt;/th&gt;
      &lt;th&gt;HDFS HA&lt;/th&gt;
      &lt;th&gt;Tests&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS 7&lt;/td&gt;
      &lt;td&gt;1.2.1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.3.6&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Unit tests and Integration Tests&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS 7&lt;/td&gt;
      &lt;td&gt;2.2.0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.3.6&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Unit tests and Integration Tests&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</description>
        <pubDate>Sun, 18 Sep 2016 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-1.6.6/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-1.6.6/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 1.8.0</title>
        <description>&lt;p&gt;Apache Accumulo 1.8.0 is a significant release that includes many important
milestone features which expand the functionality of Accumulo. These include
features related to security, availability, and extensibility. Over
350 JIRA issues were resolved in this version. This includes over
200 bug fixes and 71 improvements and 4 new features. See &lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12312121&amp;amp;version=12329879&quot;&gt;JIRA&lt;/a&gt;
for the complete list.&lt;/p&gt;

&lt;p&gt;Below are resources for this release:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/1.8/accumulo_user_manual.html&quot;&gt;User Manual&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.8/apidocs&quot;&gt;Javadocs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.8/examples&quot;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the context of Accumulo’s &lt;a href=&quot;http://semver.org&quot;&gt;Semantic Versioning&lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/blob/1.8/README.md#api&quot;&gt;guidelines&lt;/a&gt;,
this is a “minor version”. This means that new APIs have been created, some
deprecations may have been added, but no deprecated APIs have been removed.
Code written against 1.7.x should work against 1.8.0 – binary compatibility
has been preserved with one exception of an already-deprecated Mock Accumulo
utility class. As always, the Accumulo developers take API compatibility
very seriously and have invested much time to ensure that we meet the promises set forth to our users.&lt;/p&gt;

&lt;h2 id=&quot;major-changes&quot;&gt;Major Changes&lt;/h2&gt;

&lt;h3 id=&quot;speed-up-wal-roll-overs&quot;&gt;Speed up WAL roll overs&lt;/h3&gt;

&lt;p&gt;Performance of writing mutations is improved by refactoring the
bookeeping required for Write-Ahead Log (WAL) files and by creating a
standby WAL for faster switching when the log is full. This was a
substantial refactor in the way WALs worked, but smoothes overall
ingest performance in addition to provides a increase in write speed
as shown by the simple test below. The top entry is before
&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-3423&quot;&gt;ACCUMULO-3423&lt;/a&gt; and the bottom graph is after the
refactor.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12705402/WAL-slowdown-graphs.jpg&quot; alt=&quot;Graph of WAL speed up after ACCUMULO-3423&quot; title=&quot;Graph of WAL speed up after ACCUMULO-3423&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;user-level-api-for-rfile&quot;&gt;User level API for RFile&lt;/h3&gt;

&lt;p&gt;Previously the only public API available to write RFiles was via the AccumuloFileOutputFormat. There was no way to read RFiles in the public
API. &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4165&quot;&gt;ACCUMULO-4165&lt;/a&gt; exposes a brand new public &lt;a href=&quot;/1.8/apidocs/org/apache/accumulo/core/client/rfile/RFile.html&quot;&gt;API&lt;/a&gt; for reading and writing RFiles as well as cleans up some of the internal APIs.&lt;/p&gt;

&lt;h3 id=&quot;suspend-tablet-assignment-for-rolling-restarts&quot;&gt;Suspend Tablet assignment for rolling restarts&lt;/h3&gt;

&lt;p&gt;When a tablet server dies, Accumulo attempted to reassign the tablets as quickly as possible to maintain availability.
A new configuration property &lt;code class=&quot;highlighter-rouge&quot;&gt;table.suspend.duration&lt;/code&gt; (with a default of zero seconds) now controls how long to wait before reassigning
a tablet from a dead tserver. The property is configurable via the
Accumulo shell, so you can set it, do a rolling restart, and then
set it back to 0. A new state as introduced, TableState.SUSPENDED to support this feature. By default, metadata tablet
reassignment is not suspended, but that can also be changed with the &lt;code class=&quot;highlighter-rouge&quot;&gt;master.metadata.suspendable&lt;/code&gt; property that is false by
default. Root tablet assignment can not be suspended. See &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4353&quot;&gt;ACCUMULO-4353&lt;/a&gt; for more info.&lt;/p&gt;

&lt;h3 id=&quot;run-multiple-tablet-servers-on-one-node&quot;&gt;Run multiple Tablet Servers on one node&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4328&quot;&gt;ACCUMULO-4328&lt;/a&gt; introduces the capability of running multiple tservers on a single node. This is intended for nodes with a large
amounts of memory and/or disk. This feature is disabled by default. There are several related tickets: &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4072&quot;&gt;ACCUMULO-4072&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4331&quot;&gt;ACCUMULO-4331&lt;/a&gt;
and &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4406&quot;&gt;ACCUMULO-4406&lt;/a&gt;. Note that when this is enabled, the names of the log files change. Previous log file names were defined in the
generic_logger.xml as &lt;code class=&quot;highlighter-rouge&quot;&gt;${org.apache.accumulo.core.application}_{org.apache.accumulo.core.ip.localhost.hostname}.log&lt;/code&gt;.
The files will now include the instance id after the application with
&lt;code class=&quot;highlighter-rouge&quot;&gt;${org.apache.accumulo.core.application}_${instance}_${org.apache.accumulo.core.ip.localhost.hostname}.log&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For example: tserver_host.domain.com.log will become tserver_1_host.domain.log when multiple TabletServers
are run per host. The same change also applies to the debug logs provided in the example configurations. The log
names do not change if this feature is not used.&lt;/p&gt;

&lt;h3 id=&quot;rate-limiting-major-compactions&quot;&gt;Rate limiting Major Compactions&lt;/h3&gt;

&lt;p&gt;Major Compactions can significantly increase the amount of load on
TabletServers. &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4187&quot;&gt;ACCUMULO-4187&lt;/a&gt; restricts the rate at which data is
read and written when performing major compactions. This has a direct
effect on the IO load caused by major compactions with a similar
effect on the CPU utilization. This behavior is controlled by a new
property &lt;code class=&quot;highlighter-rouge&quot;&gt;tserver.compaction.major.throughput&lt;/code&gt; with a defaults of 0B
which disables the rate limiting.&lt;/p&gt;

&lt;h3 id=&quot;table-sampling&quot;&gt;Table Sampling&lt;/h3&gt;

&lt;p&gt;Queryable sample data was added by &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-3913&quot;&gt;ACCUMULO-3913&lt;/a&gt;.  This allows users to configure a pluggable
function to generate sample data.  At scan time, the sample data can optionally be scanned.
Iterators also have access to sample data.  Iterators can access all data and sample data, this
allows an iterator to use sample data for query optimizations.  The new user level RFile API
supports writing RFiles with sample data for bulk import.&lt;/p&gt;

&lt;p&gt;A simple configurable sampler function is included with Accumulo.  This sampler uses hashing and
can be configured to use a subset of Key fields.  For example if it was desired to have entire rows
in the sample, then this sampler would be configured to hash+mod the row.   Then when a row is
selected for the sample, all of its columns and all of its updates will be in the sample data.
Another scenario is one in which a document id is in the column qualifier.  In this scenario, one
would either want all data related to a document in the sample data or none.  To achieve this, the
sample could be configured to hash+mod on the column qualifier.  See the sample &lt;a href=&quot;/1.8/examples/sample&quot;&gt;Readme
example&lt;/a&gt; and javadocs on the new APIs for more information.&lt;/p&gt;

&lt;p&gt;For sampling to work, all tablets scanned must have pre-generated sample data that was generated in
the same way.  If this is not the case then scans will fail.  For existing tables, samples can be
generated by configuring sampling on the table and compacting the table.&lt;/p&gt;

&lt;h3 id=&quot;upgrade-to-apache-thrift-093&quot;&gt;Upgrade to Apache Thrift 0.9.3&lt;/h3&gt;

&lt;p&gt;Accumulo relies on Apache Thrift to implement remote procedure calls
between Accumulo services. Ticket &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4077&quot;&gt;ACCUMULO-4077&lt;/a&gt;
updates our dependency to 0.9.3. See the
&lt;a href=&quot;https://github.com/apache/thrift/blob/0.9.3/CHANGES&quot;&gt;Apache Thrift 0.9.3 Release Notes&lt;/a&gt; for details on
the changes to Thrift.  &lt;strong&gt;NOTE:&lt;/strong&gt; The Thrift 0.9.3 Java library is not
compatible other versions of Thrift. Applications running against Accumulo
1.8 must use Thrift 0.9.3. Different versions of Thrift on the classpath
will not work.&lt;/p&gt;

&lt;h3 id=&quot;iterator-test-harness&quot;&gt;Iterator Test Harness&lt;/h3&gt;

&lt;p&gt;Users often write a new iterator without fully understanding its limits and lifetime. Previously, Accumulo did
not provide any means in which a user could test iterators to catch common issues that only become apparent
in multi-node production deployments. &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-626&quot;&gt;ACCUMULO-626&lt;/a&gt; provides a framework and a collection of initial tests
which can be used to simulate common issues with Iterators that only appear in production deployments. This test
harness can be used directly by users as a supplemental tool to unit tests and integration tests with MiniAccumuloCluster.&lt;/p&gt;

&lt;p&gt;Please see the &lt;a href=&quot;/1.8/accumulo_user_manual.html#_iterator_testing&quot;&gt;Accumulo User Manual chapter on Iterator Testing&lt;/a&gt; for more information&lt;/p&gt;

&lt;h3 id=&quot;default-port-for-monitor-changed-to-9995&quot;&gt;Default port for Monitor changed to 9995&lt;/h3&gt;

&lt;p&gt;Previously, the default port for the monitor was 50095. You will need to update your links to point to port 9995. The default
port for the GC process was also changed from 50091 to 9998, although this an RPC port used internally and automatically discovered.
These default ports were changed because the previous defaults fell in the Linux Ephemeral port range. This means that the operating
system, when a port in this range was unusued, would allocate this port for dynamic network communication. This has the side-effect of
temporal bind issues when trying to start these services (as the operating
system might have allocated them elsewhere). By moving these
defaults out of the ephemeral range, we can guarantee that the Monitor and GC
will reliably start. These values are still configurable by setting
&lt;code class=&quot;highlighter-rouge&quot;&gt;monitor.port.client&lt;/code&gt;and &lt;code class=&quot;highlighter-rouge&quot;&gt;gc.port.client&lt;/code&gt; in the accumulo-site.xml.&lt;/p&gt;

&lt;h2 id=&quot;other-notable-changes&quot;&gt;Other Notable Changes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-1055&quot;&gt;ACCUMULO-1055&lt;/a&gt; Configurable maximum file size for merging minor compactions&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-1124&quot;&gt;ACCUMULO-1124&lt;/a&gt; Optimization of RFile index&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-2883&quot;&gt;ACCUMULO-2883&lt;/a&gt; API to fetch current tablet assignments&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-3871&quot;&gt;ACCUMULO-3871&lt;/a&gt; Support for running integration tests in MapReduce&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-3920&quot;&gt;ACCUMULO-3920&lt;/a&gt; Deprecate the MockAccumulo class and remove usage in our tests&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4339&quot;&gt;ACCUMULO-4339&lt;/a&gt; Make hadoop-minicluster optional dependency of acccumulo-minicluster&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4318&quot;&gt;ACCUMULO-4318&lt;/a&gt; BatchWriter, ConditionalWriter, and ScannerBase now extend AutoCloseable&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4326&quot;&gt;ACCUMULO-4326&lt;/a&gt; Value constructor now accepts Strings (and Charsequences)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4354&quot;&gt;ACCUMULO-4354&lt;/a&gt; Bump dependency versions to include gson, jetty, and sl4j&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-3735&quot;&gt;ACCUMULO-3735&lt;/a&gt; Bulk Import status page on the monitor&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4066&quot;&gt;ACCUMULO-4066&lt;/a&gt; Reduced time to processes conditional mutations.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4164&quot;&gt;ACCUMULO-4164&lt;/a&gt; Reduced seek time for cached data.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;testing&quot;&gt;Testing&lt;/h2&gt;

&lt;p&gt;Each unit and functional test only runs on a single node, while the RandomWalk
and Continuous Ingest tests run on any number of nodes. &lt;em&gt;Agitation&lt;/em&gt; refers to
randomly restarting Accumulo processes and Hadoop Datanode processes, and, in
HDFS High-Availability instances, forcing NameNode failover.&lt;/p&gt;

&lt;table id=&quot;release_notes_testing&quot; class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;OS/Environment&lt;/th&gt;
      &lt;th&gt;Hadoop&lt;/th&gt;
      &lt;th&gt;Nodes&lt;/th&gt;
      &lt;th&gt;ZooKeeper&lt;/th&gt;
      &lt;th&gt;HDFS HA&lt;/th&gt;
      &lt;th&gt;Tests&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS7/openJDK7/EC2; 3 m3.xlarge leaders, 8 d2.xlarge workers&lt;/td&gt;
      &lt;td&gt;2.6.4&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;3.4.8&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;24 HR Continuous Ingest without Agitation.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS7/openJDK7/EC2; 3 m3.xlarge leaders, 8 d2.xlarge workers&lt;/td&gt;
      &lt;td&gt;2.6.4&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;3.4.8&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;16 HR Continuous Ingest with Agitation.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS7/openJDK7/OpenStack VMs (16G RAM 2cores 2disk3; 1 leader, 5 workers&lt;/td&gt;
      &lt;td&gt;HDP 2.5 (Hadoop 2.7)&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;HDP 2.5 (ZK 3.4)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;24 HR Continuous Ingest without Agitation.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS7/openJDK7/OpenStack VMs (16G RAM 2cores 2disk3; 1 leader, 5 workers&lt;/td&gt;
      &lt;td&gt;HDP 2.5 (Hadoop 2.7)&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;HDP 2.5 (ZK 3.4)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;24 HR Continuous Ingest with Agitation.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</description>
        <pubDate>Tue, 06 Sep 2016 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-1.8.0/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-1.8.0/</guid>
        
        
        <category>release</category>
        
      </item>
    
  </channel>
</rss>
